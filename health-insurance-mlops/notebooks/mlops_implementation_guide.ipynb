{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c04eb47",
   "metadata": {},
   "source": [
    "# End-to-End MLOps Implementation Guide for Health Insurance Claims\n",
    "\n",
    "This notebook provides a comprehensive guide to implementing MLOps practices for the health insurance claims prediction project. We'll cover everything from initial setup to production deployment and monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b123f",
   "metadata": {},
   "source": [
    "## 1. Problem Definition & Environment Setup\n",
    "\n",
    "### Business Objective\n",
    "- Predict health insurance claim costs accurately\n",
    "- Reduce prediction error to optimize premium pricing\n",
    "- Automate the end-to-end ML pipeline\n",
    "\n",
    "### Technical Stack\n",
    "- **Languages & Frameworks**: Python, scikit-learn, FastAPI\n",
    "- **MLOps Tools**: MLflow, Docker, Kubernetes\n",
    "- **Cloud Platform**: AWS (can be adapted for GCP/Azure)\n",
    "- **Monitoring**: Prometheus, Grafana\n",
    "- **CI/CD**: GitHub Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.39.9-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting great-expectations\n",
      "  Downloading great_expectations-1.5.5-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting feast\n",
      "  Downloading feast-0.50.0-py2.py3-none-any.whl.metadata (36 kB)\n",
      "Collecting evidently\n",
      "  Downloading evidently-0.7.11-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: prometheus-client in /home/codespace/.local/lib/python3.12/site-packages (0.22.1)\n",
      "Collecting mlflow-skinny==3.1.1 (from mlflow)\n",
      "  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow) (3.10.3)\n",
      "Requirement already satisfied: numpy<3 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow) (2.3.1)\n",
      "Requirement already satisfied: pandas<3 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow) (2.3.1)\n",
      "Collecting pyarrow<21,>=4.0.0 (from mlflow)\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow) (1.7.0)\n",
      "Requirement already satisfied: scipy<2 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow) (1.16.0)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading databricks_sdk-0.59.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<26 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow-skinny==3.1.1->mlflow) (25.0)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3,>=1.10.8 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.4)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.1)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (2025.7.9)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow)\n",
      "  Downloading greenlet-3.2.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/codespace/.local/lib/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.1->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/codespace/.local/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.1.1->mlflow) (0.16.0)\n",
      "Collecting botocore<1.40.0,>=1.39.9 (from boto3)\n",
      "  Downloading botocore-1.39.9-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
      "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting altair<5.0.0,>=4.2.1 (from great-expectations)\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cryptography>=3.2 (from great-expectations)\n",
      "  Using cached cryptography-45.0.5-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from great-expectations) (4.24.0)\n",
      "Collecting marshmallow<4.0.0,>=3.7.1 (from great-expectations)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: mistune>=0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from great-expectations) (3.1.3)\n",
      "Collecting posthog<6,>3 (from great-expectations)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ruamel.yaml>=0.16 (from great-expectations)\n",
      "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tqdm>=4.59.0 (from great-expectations)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tzlocal>=1.2 (from great-expectations)\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pandas<3 (from mlflow)\n",
      "  Downloading pandas-2.1.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting entrypoints (from altair<5.0.0,>=4.2.1->great-expectations)\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting toolz (from altair<5.0.0,>=4.2.1->great-expectations)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting numpy<3 (from mlflow)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6,>3->great-expectations)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog<6,>3->great-expectations)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: colorama<1,>=0.3.9 in /home/codespace/.local/lib/python3.12/site-packages (from feast) (0.4.6)\n",
      "Collecting dill~=0.3.0 (from feast)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mmh3 (from feast)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "INFO: pip is looking at multiple versions of feast to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting feast\n",
      "  Downloading feast-0.49.0-py2.py3-none-any.whl.metadata (36 kB)\n",
      "Collecting pyarrow<21,>=4.0.0 (from mlflow)\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pydantic<3,>=1.10.8 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pygments<3,>=2.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from feast) (2.19.2)\n",
      "Collecting tabulate<1,>=0.8.0 (from feast)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tenacity<9,>=7 (from feast)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<1,>=0.10.0 (from feast)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typeguard>=4.0.0 (from feast)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting uvicorn-worker (from feast)\n",
      "  Downloading uvicorn_worker-0.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting dask>=2024.2.1 (from dask[dataframe]>=2024.2.1->feast)\n",
      "  Downloading dask-2025.7.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.12/site-packages (from feast) (7.0.0)\n",
      "Collecting bigtree>=0.19.2 (from feast)\n",
      "  Downloading bigtree-0.29.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting pyjwt (from feast)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]==0.34.0->feast)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]==0.34.0->feast)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]==0.34.0->feast)\n",
      "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]==0.34.0->feast)\n",
      "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]==0.34.0->feast)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting plotly<6,>=5.10.0 (from evidently)\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting statsmodels>=0.12.2 (from evidently)\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting nltk>=3.6.7 (from evidently)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting litestar>=2.8.3 (from evidently)\n",
      "  Downloading litestar-2.16.0-py3-none-any.whl.metadata (110 kB)\n",
      "Collecting typing-inspect>=0.9.0 (from evidently)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting watchdog>=3.0.0 (from evidently)\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Collecting typer>=0.3 (from evidently)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting rich>=13 (from evidently)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting iterative-telemetry>=0.0.5 (from evidently)\n",
      "  Downloading iterative_telemetry-0.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting dynaconf>=3.2.4 (from evidently)\n",
      "  Downloading dynaconf-3.2.11-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: fsspec>=2024.6.1 in /home/codespace/.local/lib/python3.12/site-packages (from evidently) (2024.6.1)\n",
      "Collecting ujson>=5.4.0 (from evidently)\n",
      "  Downloading ujson-5.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting deprecation>=2.1.0 (from evidently)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting uuid6>=2024.7.10 (from evidently)\n",
      "  Downloading uuid6-2025.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/codespace/.local/lib/python3.12/site-packages (from cryptography>=3.2->great-expectations) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=3.2->great-expectations) (2.22)\n",
      "Collecting partd>=1.4.0 (from dask>=2024.2.1->dask[dataframe]>=2024.2.1->feast)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting appdirs (from iterative-telemetry>=0.0.5->evidently)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from iterative-telemetry>=0.0.5->evidently) (3.13.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=2.5.1->great-expectations) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=2.5.1->great-expectations) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=2.5.1->great-expectations) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema>=2.5.1->great-expectations) (0.26.0)\n",
      "Requirement already satisfied: httpx>=0.22 in /home/codespace/.local/lib/python3.12/site-packages (from litestar>=2.8.3->evidently) (0.28.1)\n",
      "Collecting litestar-htmx>=0.4.0 (from litestar>=2.8.3->evidently)\n",
      "  Downloading litestar_htmx-0.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting msgspec>=0.18.2 (from litestar>=2.8.3->evidently)\n",
      "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting multidict>=6.0.2 (from litestar>=2.8.3->evidently)\n",
      "  Downloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting multipart>=1.2.0 (from litestar>=2.8.3->evidently)\n",
      "  Downloading multipart-1.2.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting polyfactory>=2.6.3 (from litestar>=2.8.3->evidently)\n",
      "  Downloading polyfactory-2.22.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting rich-click (from litestar>=2.8.3->evidently)\n",
      "  Downloading rich_click-1.8.9-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.22->litestar>=2.8.3->evidently) (1.0.9)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.6.7->evidently)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting locket (from partd>=1.4.0->dask>=2024.2.1->dask[dataframe]>=2024.2.1->feast)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting faker>=5.0.0 (from polyfactory>=2.6.3->litestar>=2.8.3->evidently)\n",
      "  Downloading faker-37.4.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13->evidently)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13->evidently)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16->great-expectations)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting mypy>=0.910 (from SQLAlchemy[mypy]>1->feast)\n",
      "  Downloading mypy-1.17.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting mypy_extensions>=1.0.0 (from mypy>=0.910->SQLAlchemy[mypy]>1->feast)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=0.9.0 (from mypy>=0.910->SQLAlchemy[mypy]>1->feast)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.12.2->evidently)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.3->evidently)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading databricks_sdk-0.59.0-py3-none-any.whl (676 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.2/676.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading starlette-0.47.1-py3-none-any.whl (72 kB)\n",
      "Downloading boto3-1.39.9-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.39.9-py3-none-any.whl (13.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
      "Downloading great_expectations-1.5.5-py3-none-any.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pandas-2.1.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading feast-0.49.0-py2.py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading evidently-0.7.11-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bigtree-0.29.2-py3-none-any.whl (105 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cryptography-45.0.5-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "Downloading dask-2025.7.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading dynaconf-3.2.11-py2.py3-none-any.whl (236 kB)\n",
      "Downloading greenlet-3.2.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (605 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.5/605.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "Downloading iterative_telemetry-0.0.10-py3-none-any.whl (10 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading litestar-2.16.0-py3-none-any.whl (573 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.2/573.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading litestar_htmx-0.5.0-py3-none-any.whl (10.0 kB)\n",
      "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading multipart-1.2.1-py3-none-any.whl (13 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading polyfactory-2.22.1-py3-none-any.whl (63 kB)\n",
      "Downloading faker-37.4.2-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.1/754.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy-1.17.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Downloading ujson-5.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "Downloading uuid6-2025.0.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading mmh3-5.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading rich_click-1.8.9-py3-none-any.whl (36 kB)\n",
      "Downloading uvicorn_worker-0.3.0-py3-none-any.whl (5.3 kB)\n",
      "Installing collected packages: appdirs, zipp, werkzeug, websockets, watchdog, uvloop, uuid6, ujson, tzlocal, typeguard, tqdm, toolz, toml, tenacity, tabulate, sqlparse, shellingham, ruamel.yaml.clib, regex, python-dotenv, pyjwt, pydantic-core, pyasn1, protobuf, pathspec, numpy, mypy_extensions, multipart, multidict, msgspec, mmh3, mdurl, marshmallow, Mako, locket, litestar-htmx, jmespath, itsdangerous, httptools, gunicorn, greenlet, graphql-core, faker, entrypoints, dynaconf, distro, dill, deprecation, cloudpickle, click, cachetools, blinker, bigtree, backoff, annotated-types, watchfiles, uvicorn, typing-inspect, starlette, sqlalchemy, ruamel.yaml, rsa, pydantic, pyasn1-modules, pyarrow, posthog, polyfactory, plotly, patsy, partd, pandas, nltk, mypy, markdown-it-py, iterative-telemetry, importlib_metadata, graphql-relay, Flask, docker, cryptography, botocore, uvicorn-worker, statsmodels, s3transfer, rich, opentelemetry-api, graphene, google-auth, fastapi, dask, alembic, typer, rich-click, opentelemetry-semantic-conventions, databricks-sdk, boto3, altair, opentelemetry-sdk, litestar, great-expectations, mlflow-skinny, feast, evidently, mlflow\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/104\u001b[0m [pathspec]core]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/104\u001b[0m [pathspec]\n",
      "\u001b[2K    Uninstalling numpy-2.3.1:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/104\u001b[0m [pathspec]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.1━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 25/104\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: plotly━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 66/104\u001b[0m [polyfactory]es]]\n",
      "\u001b[2K    Found existing installation: plotly 6.2.090m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 66/104\u001b[0m [polyfactory]\n",
      "\u001b[2K    Uninstalling plotly-6.2.0:━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 67/104\u001b[0m [plotly]]\n",
      "\u001b[2K      Successfully uninstalled plotly-6.2.0\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m 67/104\u001b[0m [plotly]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 68/104\u001b[0m [patsy]]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.1[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 68/104\u001b[0m [patsy]\n",
      "\u001b[2K    Uninstalling pandas-2.3.1:━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/104\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.1m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 70/104\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104/104\u001b[0m [mlflow] [mlflow]ly]east]-skinny]ions]entions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.1 Mako-1.3.10 alembic-1.16.4 altair-4.2.2 annotated-types-0.7.0 appdirs-1.4.4 backoff-2.2.1 bigtree-0.29.2 blinker-1.9.0 boto3-1.39.9 botocore-1.39.9 cachetools-5.5.2 click-8.2.1 cloudpickle-3.1.1 cryptography-45.0.5 dask-2025.7.0 databricks-sdk-0.59.0 deprecation-2.1.0 dill-0.3.9 distro-1.9.0 docker-7.1.0 dynaconf-3.2.11 entrypoints-0.4 evidently-0.7.11 faker-37.4.2 fastapi-0.116.1 feast-0.49.0 google-auth-2.40.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 great-expectations-1.5.5 greenlet-3.2.3 gunicorn-23.0.0 httptools-0.6.4 importlib_metadata-8.7.0 iterative-telemetry-0.0.10 itsdangerous-2.2.0 jmespath-1.0.1 litestar-2.16.0 litestar-htmx-0.5.0 locket-1.0.0 markdown-it-py-3.0.0 marshmallow-3.26.1 mdurl-0.1.2 mlflow-3.1.1 mlflow-skinny-3.1.1 mmh3-5.1.0 msgspec-0.19.0 multidict-6.6.3 multipart-1.2.1 mypy-1.17.0 mypy_extensions-1.1.0 nltk-3.9.1 numpy-1.26.4 opentelemetry-api-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 pandas-2.1.4 partd-1.4.2 pathspec-0.12.1 patsy-1.0.1 plotly-5.24.1 polyfactory-2.22.1 posthog-5.4.0 protobuf-6.31.1 pyarrow-17.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.10.6 pydantic-core-2.27.2 pyjwt-2.10.1 python-dotenv-1.1.1 regex-2024.11.6 rich-14.0.0 rich-click-1.8.9 rsa-4.9.1 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 s3transfer-0.13.1 shellingham-1.5.4 sqlalchemy-2.0.41 sqlparse-0.5.3 starlette-0.47.1 statsmodels-0.14.5 tabulate-0.9.0 tenacity-8.5.0 toml-0.10.2 toolz-1.0.0 tqdm-4.67.1 typeguard-4.4.4 typer-0.16.0 typing-inspect-0.9.0 tzlocal-5.3.1 ujson-5.10.0 uuid6-2025.0.1 uvicorn-0.34.0 uvicorn-worker-0.3.0 uvloop-0.21.0 watchdog-6.0.0 watchfiles-1.1.0 websockets-15.0.1 werkzeug-3.1.3 zipp-3.23.0\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "API request to http://localhost:5000/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=health-insurance-claims (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a14d91bd0a0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connection.py:494\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/http/client.py:1322\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1321\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/http/client.py:1081\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1084\u001b[39m \n\u001b[32m   1085\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/http/client.py:1025\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connection.py:325\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    327\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connection.py:213\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    217\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPConnection object at 0x7a14d91bd0a0>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 871 (4 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=health-insurance-claims (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a14d91bd0a0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:229\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_http_response_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackoff_jitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraise_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost_creds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrespect_retry_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.Timeout \u001b[38;5;28;01mas\u001b[39;00m to:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/mlflow/utils/request_utils.py:237\u001b[39m, in \u001b[36m_get_http_response_with_retries\u001b[39m\u001b[34m(method, url, max_retries, backoff_factor, backoff_jitter, retry_codes, raise_on_status, allow_redirects, respect_retry_after_header, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m allow_redirects = env_value \u001b[38;5;28;01mif\u001b[39;00m allow_redirects \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m allow_redirects\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/adapters.py:700\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=health-insurance-claims (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a14d91bd0a0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m MLFLOW_TRACKING_URI = \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:5000\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhealth-insurance-claims\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Configure project paths\u001b[39;00m\n\u001b[32m     15\u001b[39m BASE_DIR = Path.cwd().parent\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/mlflow/tracking/fluent.py:183\u001b[39m, in \u001b[36mset_experiment\u001b[39m\u001b[34m(experiment_name, experiment_id)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _experiment_lock:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         experiment = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment:\n\u001b[32m    185\u001b[39m             _logger.info(\n\u001b[32m    186\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mExperiment with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist. Creating a new experiment.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    187\u001b[39m                 experiment_name,\n\u001b[32m    188\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:258\u001b[39m, in \u001b[36mTrackingServiceClient.get_experiment_by_name\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m    251\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m        name: The experiment name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    256\u001b[39m \u001b[33;03m        :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:869\u001b[39m, in \u001b[36mRestStore.get_experiment_by_name\u001b[39m\u001b[34m(self, experiment_name)\u001b[39m\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    868\u001b[39m     req_body = message_to_json(GetExperimentByName(experiment_name=experiment_name))\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m     response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGetExperimentByName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Experiment.from_proto(response_proto.experiment)\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:135\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[39m\n\u001b[32m    133\u001b[39m     endpoint, method = _METHOD_TO_INFO[api]\n\u001b[32m    134\u001b[39m response_proto = api.Response()\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:585\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mGET\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    584\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     response = \u001b[43mhttp_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    587\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:252\u001b[39m, in \u001b[36mhttp_request\u001b[39m\u001b[34m(host_creds, endpoint, method, max_retries, backoff_factor, backoff_jitter, extra_headers, retry_codes, timeout, raise_on_status, respect_retry_after_header, retry_timeout_seconds, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUrlException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01miu\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed with exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mMlflowException\u001b[39m: API request to http://localhost:5000/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=health-insurance-claims (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a14d91bd0a0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\\r\\nHost: localhost:42841\\r\\nUs', b'-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.']\n",
      "Bad pipe message: %s [b'0.0 Safari/537.36\\r\\nAccept-Encoding: gzip, defla']\n",
      "Bad pipe message: %s [b', br, zstd\\r\\nAccept-Language: en-US,en;q=0.9\\r\\nCache-Control: max-age=0\\r\\nReferer: https://github.com/\\r\\nX-Request-ID: ', b'632e3f352748910f3d9526d1c4ee13\\r\\nX-Real-IP: 49.37']\n",
      "Bad pipe message: %s [b'49.116\\r\\nX-Forwarded-Port: 443\\r\\nX-Forwarded-Sc']\n",
      "Bad pipe message: %s [b'me: https\\r\\nX-Original-URI: /\\r\\nX-Scheme: https\\r\\nsec-fetch-site: cross-site\\r\\nsec-fetch-mode: navigate\\r\\nse', b'fetch-dest: document\\r\\nsec-ch-ua: \"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"138\", \"Google Chrome\";v=\"138\"\\r', b'ec-ch-ua-', b'bile: ?0\\r\\nsec-ch-ua-platform: \"Windows\"\\r\\npriority: u=0, i\\r\\nX-Original-Proto: https\\r\\nX-Forwarded-Proto: https', b'X-Forwarded-']\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install mlflow boto3 great-expectations feast evidently prometheus-client\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure MLflow\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"health-insurance-claims\")\n",
    "\n",
    "# Configure project paths\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "MLRUNS_DIR = BASE_DIR / \"mlruns\"\n",
    "\n",
    "# Create necessary directories\n",
    "for dir_path in [DATA_DIR, MODELS_DIR, MLRUNS_DIR]:\n",
    "    dir_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Environment setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01b17a",
   "metadata": {},
   "source": [
    "## 2. Data Engineering Pipeline\n",
    "\n",
    "In this section, we'll implement:\n",
    "1. Data ingestion from various sources\n",
    "2. Data validation using Great Expectations\n",
    "3. Data versioning using DVC\n",
    "4. Cloud storage integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.dataset import PandasDataset\n",
    "\n",
    "# Data ingestion function\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load data from CSV file and convert to Great Expectations dataset\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    ge_df = ge.from_pandas(df)\n",
    "    return ge_df\n",
    "\n",
    "# Data validation with Great Expectations\n",
    "def validate_data(ge_df: PandasDataset):\n",
    "    \"\"\"Validate data using Great Expectations\"\"\"\n",
    "    # Define expectations\n",
    "    ge_df.expect_column_values_to_not_be_null(\"age\")\n",
    "    ge_df.expect_column_values_to_be_between(\"age\", 0, 100)\n",
    "    ge_df.expect_column_values_to_be_between(\"bmi\", 10, 50)\n",
    "    ge_df.expect_column_values_to_be_in_set(\"smoker\", [\"yes\", \"no\"])\n",
    "    \n",
    "    # Save validation results\n",
    "    results = ge_df.validate()\n",
    "    print(f\"Validation successful: {results.success}\")\n",
    "    return results\n",
    "\n",
    "# Load and validate sample data\n",
    "try:\n",
    "    data = load_data(str(DATA_DIR / \"health_claims.csv\"))\n",
    "    validation_results = validate_data(data)\n",
    "    \n",
    "    # Log validation results to MLflow\n",
    "    with mlflow.start_run(run_name=\"data_validation\"):\n",
    "        mlflow.log_metric(\"validation_success\", int(validation_results.success))\n",
    "        mlflow.log_param(\"data_version\", \"v1.0\")\n",
    "        mlflow.log_param(\"n_rows\", len(data))\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Sample data file not found. Please ensure data is available in the data directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732164fc",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "This section covers:\n",
    "1. Feature transformation pipeline\n",
    "2. Feature store integration with Feast\n",
    "3. Feature versioning and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d70908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define feature engineering pipeline\n",
    "def create_feature_pipeline():\n",
    "    \"\"\"Create feature engineering pipeline\"\"\"\n",
    "    numeric_features = ['age', 'bmi']\n",
    "    categorical_features = ['smoker', 'region', 'gender']\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "# Create and fit the feature pipeline\n",
    "def process_features(df: pd.DataFrame):\n",
    "    \"\"\"Process features using the pipeline\"\"\"\n",
    "    feature_pipeline = create_feature_pipeline()\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"feature_engineering\"):\n",
    "        # Fit and transform the data\n",
    "        features_processed = feature_pipeline.fit_transform(df)\n",
    "        \n",
    "        # Log feature engineering parameters\n",
    "        mlflow.log_param(\"numeric_features\", ['age', 'bmi'])\n",
    "        mlflow.log_param(\"categorical_features\", ['smoker', 'region', 'gender'])\n",
    "        \n",
    "        # Log the feature pipeline\n",
    "        mlflow.sklearn.log_model(feature_pipeline, \"feature_pipeline\")\n",
    "        \n",
    "        return features_processed, feature_pipeline\n",
    "\n",
    "# Example usage (if data is available)\n",
    "try:\n",
    "    features_processed, pipeline = process_features(data)\n",
    "    print(\"Feature engineering completed successfully!\")\n",
    "except NameError:\n",
    "    print(\"Please run the data loading cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92255aa1",
   "metadata": {},
   "source": [
    "## 4. Model Development\n",
    "\n",
    "This section covers:\n",
    "1. Model training with MLflow tracking\n",
    "2. Model evaluation and selection\n",
    "3. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def train_and_evaluate_model(X, y, model_name=\"RandomForestRegressor\"):\n",
    "    \"\"\"Train and evaluate model with MLflow tracking\"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"train_{model_name}\"):\n",
    "        # Initialize and train model\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params({\n",
    "            \"model_type\": model_name,\n",
    "            \"n_estimators\": 100,\n",
    "            \"random_state\": 42\n",
    "        })\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"mse\": mse,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2\n",
    "        })\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"Model Training Results:\")\n",
    "        print(f\"MSE: {mse:.2f}\")\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        print(f\"R2 Score: {r2:.2f}\")\n",
    "        \n",
    "        return model, (X_test, y_test)\n",
    "\n",
    "# Train model if data is available\n",
    "try:\n",
    "    target = data['claim_amount']\n",
    "    model, test_data = train_and_evaluate_model(features_processed, target)\n",
    "    print(\"\\nModel training completed successfully!\")\n",
    "except NameError:\n",
    "    print(\"Please run the feature engineering cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cded2fe",
   "metadata": {},
   "source": [
    "## 5. Model Registry\n",
    "\n",
    "This section covers:\n",
    "1. Model versioning with MLflow\n",
    "2. Model staging (Development/Staging/Production)\n",
    "3. Model metadata tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Registry Management\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "def register_model(run_id, model_name=\"health_insurance_model\"):\n",
    "    \"\"\"Register model with MLflow\"\"\"\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Register the model\n",
    "    result = mlflow.register_model(\n",
    "        f\"runs:/{run_id}/model\",\n",
    "        model_name\n",
    "    )\n",
    "    \n",
    "    # Transition to staging\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=result.version,\n",
    "        stage=\"Staging\"\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_latest_model(model_name=\"health_insurance_model\", stage=\"Staging\"):\n",
    "    \"\"\"Get the latest model from registry\"\"\"\n",
    "    model = mlflow.pyfunc.load_model(\n",
    "        model_uri=f\"models:/{model_name}/{stage}\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Get the latest run ID and register the model\n",
    "try:\n",
    "    latest_run = mlflow.search_runs(\n",
    "        experiment_ids=[mlflow.get_experiment_by_name(\"health-insurance-claims\").experiment_id],\n",
    "        filter_string=\"\",\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=1\n",
    "    )\n",
    "    \n",
    "    if not latest_run.empty:\n",
    "        run_id = latest_run.iloc[0].run_id\n",
    "        model_info = register_model(run_id)\n",
    "        print(f\"Model registered successfully with version: {model_info.version}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error registering model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7617f",
   "metadata": {},
   "source": [
    "## 6. CI/CD Pipeline\n",
    "\n",
    "This section demonstrates:\n",
    "1. Setting up GitHub Actions workflow\n",
    "2. Creating Docker container\n",
    "3. Implementing automated tests\n",
    "4. Configuring deployment pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d89fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GitHub Actions workflow file\n",
    "github_workflow = \"\"\"\n",
    "name: MLOps Pipeline\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main ]\n",
    "  pull_request:\n",
    "    branches: [ main ]\n",
    "\n",
    "jobs:\n",
    "  test-and-deploy:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "    - uses: actions/checkout@v2\n",
    "    \n",
    "    - name: Set up Python\n",
    "      uses: actions/setup-python@v2\n",
    "      with:\n",
    "        python-version: '3.9'\n",
    "    \n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        python -m pip install --upgrade pip\n",
    "        pip install -r requirements.txt\n",
    "    \n",
    "    - name: Run tests\n",
    "      run: |\n",
    "        python -m pytest tests/\n",
    "    \n",
    "    - name: Build Docker image\n",
    "      run: docker build -t health-insurance-api .\n",
    "    \n",
    "    - name: Deploy to staging\n",
    "      if: github.ref == 'refs/heads/main'\n",
    "      run: |\n",
    "        # Add deployment commands here\n",
    "        echo \"Deploying to staging...\"\n",
    "\"\"\"\n",
    "\n",
    "# Write workflow file\n",
    "workflow_path = Path(\".github/workflows/mlops.yml\")\n",
    "workflow_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "workflow_path.write_text(github_workflow)\n",
    "\n",
    "print(\"GitHub Actions workflow created at: .github/workflows/mlops.yml\")\n",
    "\n",
    "# Display Dockerfile content\n",
    "dockerfile_content = \"\"\"\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "CMD [\"uvicorn\", \"app.api:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nDockerfile content:\")\n",
    "print(dockerfile_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504f233",
   "metadata": {},
   "source": [
    "## 7. Monitoring System\n",
    "\n",
    "This section covers:\n",
    "1. Setting up Prometheus metrics\n",
    "2. Implementing data drift detection\n",
    "3. Creating performance monitoring dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prometheus_client import Counter, Histogram, start_http_server\n",
    "import evidently\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.tabs import DataDriftTab, CatTargetDriftTab\n",
    "\n",
    "# Prometheus metrics\n",
    "prediction_counter = Counter('model_predictions_total', 'Total number of predictions')\n",
    "prediction_latency = Histogram('prediction_latency_seconds', 'Time spent processing prediction')\n",
    "\n",
    "# Data drift detection\n",
    "def create_drift_dashboard(reference_data, current_data, output_path=\"drift_dashboard.html\"):\n",
    "    \"\"\"Create data drift dashboard using Evidently\"\"\"\n",
    "    dashboard = Dashboard(tabs=[DataDriftTab()])\n",
    "    dashboard.calculate(reference_data, current_data)\n",
    "    dashboard.save(output_path)\n",
    "    \n",
    "    return dashboard\n",
    "\n",
    "# Example monitoring setup\n",
    "def setup_monitoring(port=8000):\n",
    "    \"\"\"Setup Prometheus monitoring\"\"\"\n",
    "    start_http_server(port)\n",
    "    print(f\"Prometheus metrics server started at port {port}\")\n",
    "    \n",
    "    # Example Prometheus metrics\n",
    "    prediction_counter.inc()\n",
    "    with prediction_latency.time():\n",
    "        # Simulate prediction\n",
    "        import time\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# Create sample drift report if data is available\n",
    "try:\n",
    "    # Split data into reference and current\n",
    "    split_idx = len(data) // 2\n",
    "    reference_data = data[:split_idx]\n",
    "    current_data = data[split_idx:]\n",
    "    \n",
    "    # Create and save drift dashboard\n",
    "    drift_dashboard = create_drift_dashboard(reference_data, current_data)\n",
    "    print(\"Drift dashboard created successfully!\")\n",
    "except NameError:\n",
    "    print(\"Please run the data loading cell first to create drift dashboard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc03dc",
   "metadata": {},
   "source": [
    "## 8. Retraining Pipeline\n",
    "\n",
    "This section covers:\n",
    "1. Setting up automated retraining triggers\n",
    "2. Implementing model retraining workflow\n",
    "3. Validating retrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e92fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "class ModelRetrainingPipeline:\n",
    "    def __init__(self, model_name, performance_threshold=0.7):\n",
    "        self.model_name = model_name\n",
    "        self.performance_threshold = performance_threshold\n",
    "    \n",
    "    def check_performance_degradation(self, current_performance):\n",
    "        \"\"\"Check if model performance is below threshold\"\"\"\n",
    "        return current_performance < self.performance_threshold\n",
    "    \n",
    "    def check_data_drift(self, reference_data, current_data, drift_threshold=0.1):\n",
    "        \"\"\"Check for significant data drift\"\"\"\n",
    "        # Using Evidently for drift detection\n",
    "        drift_report = Dashboard(tabs=[DataDriftTab()])\n",
    "        drift_report.calculate(reference_data, current_data)\n",
    "        \n",
    "        # Extract drift score (simplified)\n",
    "        drift_detected = any(drift_report.dataframes[0]['metrics'])\n",
    "        return drift_detected\n",
    "    \n",
    "    def retrain_model(self, new_data):\n",
    "        \"\"\"Retrain model with new data\"\"\"\n",
    "        with mlflow.start_run(run_name=f\"retraining_{datetime.now().strftime('%Y%m%d')}\"):\n",
    "            # Preprocess new data\n",
    "            X, y = self.prepare_data(new_data)\n",
    "            \n",
    "            # Train new model\n",
    "            model = RandomForestRegressor(random_state=42)\n",
    "            model.fit(X, y)\n",
    "            \n",
    "            # Log metrics\n",
    "            train_score = model.score(X, y)\n",
    "            mlflow.log_metric(\"training_score\", train_score)\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(model, \"retrained_model\")\n",
    "            \n",
    "            return model, train_score\n",
    "    \n",
    "    def validate_retrained_model(self, new_model, validation_data):\n",
    "        \"\"\"Validate the retrained model\"\"\"\n",
    "        X_val, y_val = self.prepare_data(validation_data)\n",
    "        score = new_model.score(X_val, y_val)\n",
    "        \n",
    "        if score > self.performance_threshold:\n",
    "            return True, score\n",
    "        return False, score\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_data(data):\n",
    "        \"\"\"Prepare data for model training\"\"\"\n",
    "        X = data.drop('claim_amount', axis=1)\n",
    "        y = data['claim_amount']\n",
    "        return X, y\n",
    "\n",
    "# Example usage\n",
    "retraining_pipeline = ModelRetrainingPipeline(\n",
    "    model_name=\"health_insurance_model\",\n",
    "    performance_threshold=0.7\n",
    ")\n",
    "\n",
    "# Simulate retraining decision\n",
    "try:\n",
    "    current_performance = 0.65  # Simulated degraded performance\n",
    "    if retraining_pipeline.check_performance_degradation(current_performance):\n",
    "        print(\"Performance degradation detected. Initiating retraining...\")\n",
    "        \n",
    "        # In practice, you would:\n",
    "        # 1. Load new training data\n",
    "        # 2. Retrain model\n",
    "        # 3. Validate new model\n",
    "        # 4. Deploy if validation passes\n",
    "except Exception as e:\n",
    "    print(f\"Error in retraining pipeline: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd78b7",
   "metadata": {},
   "source": [
    "## 9. Security and Governance\n",
    "\n",
    "This section covers:\n",
    "1. Implementing IAM roles and permissions\n",
    "2. Setting up audit logging\n",
    "3. Ensuring HIPAA compliance\n",
    "4. Implementing model governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1674aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "class ModelGovernance:\n",
    "    def __init__(self):\n",
    "        # Setup logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            filename='model_governance.log'\n",
    "        )\n",
    "        self.logger = logging.getLogger('ModelGovernance')\n",
    "    \n",
    "    def log_model_access(self, user_id, model_version, action):\n",
    "        \"\"\"Log model access\"\"\"\n",
    "        log_entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'user_id': user_id,\n",
    "            'model_version': model_version,\n",
    "            'action': action\n",
    "        }\n",
    "        self.logger.info(f\"Model Access: {json.dumps(log_entry)}\")\n",
    "    \n",
    "    def verify_data_compliance(self, data, sensitive_columns=['ssn', 'phone']):\n",
    "        \"\"\"Verify data compliance with HIPAA\"\"\"\n",
    "        # Check for sensitive columns\n",
    "        for col in sensitive_columns:\n",
    "            if col in data.columns:\n",
    "                raise ValueError(f\"Sensitive column {col} must be encrypted or removed\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def hash_sensitive_data(self, value):\n",
    "        \"\"\"Hash sensitive data\"\"\"\n",
    "        return hashlib.sha256(str(value).encode()).hexdigest()\n",
    "    \n",
    "    def audit_model_training(self, model_params, training_data_hash):\n",
    "        \"\"\"Audit model training process\"\"\"\n",
    "        audit_record = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_params': model_params,\n",
    "            'training_data_hash': training_data_hash,\n",
    "            'environment': self.get_environment_info()\n",
    "        }\n",
    "        self.logger.info(f\"Model Training Audit: {json.dumps(audit_record)}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_environment_info():\n",
    "        \"\"\"Get information about the training environment\"\"\"\n",
    "        import sys\n",
    "        import platform\n",
    "        \n",
    "        return {\n",
    "            'python_version': sys.version,\n",
    "            'platform': platform.platform(),\n",
    "            'dependencies': mlflow.get_tracking_uri()\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "governance = ModelGovernance()\n",
    "\n",
    "# Simulate model access logging\n",
    "governance.log_model_access(\n",
    "    user_id=\"data_scientist_1\",\n",
    "    model_version=\"v1.0.0\",\n",
    "    action=\"model_training\"\n",
    ")\n",
    "\n",
    "# Example of data compliance check\n",
    "try:\n",
    "    if 'data' in globals():\n",
    "        governance.verify_data_compliance(data)\n",
    "        print(\"Data compliance verification passed!\")\n",
    "    \n",
    "    # Audit model training\n",
    "    model_params = {\n",
    "        'algorithm': 'RandomForest',\n",
    "        'parameters': {'n_estimators': 100, 'random_state': 42}\n",
    "    }\n",
    "    data_hash = \"sample_hash_value\"  # In practice, calculate this from actual data\n",
    "    governance.audit_model_training(model_params, data_hash)\n",
    "    print(\"Model training audit logged successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Governance check failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3739418",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated a complete MLOps implementation for the health insurance claims prediction project, including:\n",
    "\n",
    "1. Environment setup and configuration\n",
    "2. Data engineering and validation\n",
    "3. Feature engineering and tracking\n",
    "4. Model development with MLflow\n",
    "5. Model versioning and registry\n",
    "6. CI/CD pipeline setup\n",
    "7. Monitoring and observability\n",
    "8. Automated retraining pipeline\n",
    "9. Security and governance implementation\n",
    "\n",
    "Next steps:\n",
    "1. Deploy the model to production\n",
    "2. Set up automated monitoring alerts\n",
    "3. Implement automated retraining triggers\n",
    "4. Establish regular security audits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
